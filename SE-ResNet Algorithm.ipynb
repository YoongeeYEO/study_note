{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPREvT8opVOgMeQF9bWBb5M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 논문제목\n","  * An Experimental Comparison of CNN-based Deep Learning Algorithms for Recognition of Beauty-related Skin Disease - Chang-Hui Bae*, Won-Young Cho*, Hyeong-Jun Kim*, Ok-Kyoon Ha(2020)"],"metadata":{"id":"sZP01ZvwXKEh"}},{"cell_type":"markdown","source":["# 주요내용\n","* 본 논문에서는 딥러닝 지도학습 알고리즘을 사용한 학습 모델을 대상으로 미용 관련 피부질환 인식의 효과성을 실험적으로 비교한다. 최근 딥러닝 기술을 산업, 교육, 의료 등 다양한 분야에 적용하고 있으며, 의료 분야에서는 중요 피부질환 중 하나인 피부암 식별의 수준을 전문가 수준 으로 높인 성과를 보이고 있다.\n","* 딥러닝 기반 이미지 분류에 활용도가 높은 CNN 알고리즘을 비롯하여 ResNet, SE-ResNet 등을 적용하여 실험적으로 정확도를 비교함으로써 미용 관련 피부질환을 판단하는 효과성을 평가함.\n","* 그 결과, 각 알고리즘을 적용한 학습 모델을 실험한 결과에서 CNN의 경우 평균 71.5%, ResNet은 평균 90.6%, SE-ResNet은 평균 95.3%의 정확도를 보임. 특히 학습 깊이를 다르게하여 비교한 결과 50개의 계층 구조를 갖는 SE-ResNet-50 모델이 평균 96.2%의 정확도로 미용 관련 피부질환 식별을 위해 가장 효과적인 결과를 보임."],"metadata":{"id":"TiVVUanUXXMJ"}},{"cell_type":"markdown","source":["# SE-ResNet 모델 특징\n","* SE-ResNet은 ResNet의 Residual 모듈 다음 단계에 SENet의 SE block을 추가한 것\n","* SE block은 CNN 계열의 알고리즘의 컨볼루션 단계에서 생성된 특성을 채널별 중요도를 고려하여 재보정(Recalibration)\n","* SE block 내부의 Global pooling을 통해 다수 채널의 특성맵들을 대상으로 하나의 값으로 압축하 고, 두 개의 Fully-connected층과 시그모이드 단계를 거쳐 채널별 상대적 중요도를 반영하여 활성화함으로써 재보정이 가능하게 함\n","* 이러한 특성으로 SENet의 SE block은 각 채널의 특성맵을 추출하여 압축(Squeeze)하고, 재조정하는 과정에서 채널 간 의존성을 계산하여 활성화(Excitation) -> 추가적인 연산량이 적으면서도 우수한 성능의 모델 생성 가능"],"metadata":{"id":"MARawQM2ZX7A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E6JbLj6qXDfr"},"outputs":[],"source":["# SE-ResNet50 Model Sample Code\n","\n","from __future__ import print_function\n","from __future__ import absolute_import\n","\n","import warnings\n","\n","from keras.layers import Input\n","from keras import layers\n","from keras.layers import Dense\n","from keras.layers import Activation\n","from keras.layers import Flatten\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import AveragePooling2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras.layers import GlobalMaxPooling2D\n","from keras.layers import BatchNormalization\n","from keras.layers import Reshape\n","from keras.layers import Multiply\n","from keras.models import Model\n","from keras import backend as K\n","from keras.utils.layer_utils import get_source_inputs\n","from keras.utils import layer_utils\n","from keras.utils.data_utils import get_file\n","\n","!pip install keras_applications\n","!pip install keras_preprocessing\n","from keras_applications.imagenet_utils import _obtain_input_shape\n","\n","def preprocess_input(x):\n","    # 'RGB'->'BGR'\n","    x = x[..., ::-1]\n","    \n","    # Zero-center by mean pixel\n","    x[..., 0] -= 103.939\n","    x[..., 1] -= 116.779\n","    x[..., 2] -= 123.68\n","\n","    # Scale\n","    x *= 0.017\n","    return x\n","  \n","def identity_block(input_tensor, kernel_size, filters, stage, block):\n","    filters1, filters2, filters3 = filters\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    bn_eps = 0.0001\n","        \n","    block_name = str(stage) + \"_\" + str(block)\n","    conv_name_base = \"conv\" + block_name\n","    relu_name_base = \"relu\" + block_name\n","\n","    x = Conv2D(filters1, (1, 1), use_bias=False, name=conv_name_base + '_x1')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x1_bn')(x)\n","    x = Activation('relu', name=relu_name_base + '_x1')(x)\n","\n","    x = Conv2D(filters2, kernel_size, padding='same', use_bias=False, name=conv_name_base + '_x2')(x)\n","    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x2_bn')(x)\n","    x = Activation('relu', name=relu_name_base + '_x2')(x)\n","\n","    x = Conv2D(filters3, (1, 1), use_bias=False, name=conv_name_base + '_x3')(x)\n","    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x3_bn')(x)\n","\n","    se = GlobalAveragePooling2D(name='pool' + block_name + '_gap')(x)\n","    se = Dense(filters3 // 16, activation='relu', name = 'fc' + block_name + '_sqz')(se)\n","    se = Dense(filters3, activation='sigmoid', name = 'fc' + block_name + '_exc')(se)\n","    se = Reshape([1, 1, filters3])(se)\n","    x = Multiply(name='scale' + block_name)([x, se])\n","\n","    x = layers.add([x, input_tensor], name='block_' + block_name)\n","    x = Activation('relu', name=relu_name_base)(x)\n","    return x\n","\n","\n","def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n","    filters1, filters2, filters3 = filters\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    bn_eps = 0.0001\n","    \n","    block_name = str(stage) + \"_\" + str(block)\n","    conv_name_base = \"conv\" + block_name\n","    relu_name_base = \"relu\" + block_name\n","\n","    x = Conv2D(filters1, (1, 1), use_bias=False, name=conv_name_base + '_x1')(input_tensor)\n","    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x1_bn')(x)\n","    x = Activation('relu', name=relu_name_base + '_x1')(x)\n","\n","    x = Conv2D(filters2, kernel_size, strides=strides, padding='same', use_bias=False, name=conv_name_base + '_x2')(x)\n","    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x2_bn')(x)\n","    x = Activation('relu', name=relu_name_base + '_x2')(x)\n","\n","    x = Conv2D(filters3, (1, 1), use_bias=False, name=conv_name_base + '_x3')(x)\n","    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_x3_bn')(x)\n","    \n","    se = GlobalAveragePooling2D(name='pool' + block_name + '_gap')(x)\n","    se = Dense(filters3 // 16, activation='relu', name = 'fc' + block_name + '_sqz')(se)\n","    se = Dense(filters3, activation='sigmoid', name = 'fc' + block_name + '_exc')(se)\n","    se = Reshape([1, 1, filters3])(se)\n","    x = Multiply(name='scale' + block_name)([x, se])\n","    \n","    shortcut = Conv2D(filters3, (1, 1), strides=strides, use_bias=False, name=conv_name_base + '_prj')(input_tensor)\n","    shortcut = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name=conv_name_base + '_prj_bn')(shortcut)\n","\n","    x = layers.add([x, shortcut], name='block_' + block_name)\n","    x = Activation('relu', name=relu_name_base)(x)\n","    return x\n","\n","\n","def SEResNet50(include_top=True, weights='imagenet',\n","               input_tensor=None, input_shape=None,\n","               pooling=None,\n","               classes=1000):\n","\n","    # Determine proper input shape\n","    input_shape = _obtain_input_shape(input_shape,\n","                                      default_size=225,\n","                                      min_size=160,\n","                                      data_format=K.image_data_format(),\n","                                      require_flatten=include_top,\n","                                      weights=weights)\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","    if K.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    bn_eps = 0.0001\n","\n","    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', use_bias=False, name='conv1')(img_input)\n","    x = BatchNormalization(axis=bn_axis, epsilon=bn_eps, name='conv1_bn')(x)\n","    x = Activation('relu', name='relu1')(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n","\n","    x = conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n","\n","    x = conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n","\n","    x = conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n","\n","    x = conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n","\n","    x = Flatten()(x)\n","    x = Dense(classes, activation='softmax', name='fc6')(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","    # Create model.\n","    model = Model(inputs, x, name='se-resnet50')\n","    return model  "]},{"cell_type":"markdown","source":["* 웹캠/스마트폰 등을 활용한 피부질환 진단(classification) 프로젝트를 수행하다가 우연히 참고하게된 논문이다.\n","* 피부질환 분류에서 CNN 기반 다양한 모델 알고리즘을 비교하여 실험한 결과 SE-ResNet 알고리즘 기반의 학습 모델이 평균 95.3%로 가장 높았음을 감안하여, 수행중인 프로젝트에서도 SE-ResNet 알고리즘 기반의 모델을 학습시켜 결과를 확인해볼 예정이다."],"metadata":{"id":"d_pgk74aaVYh"}}]}